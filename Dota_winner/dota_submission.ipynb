{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Dota 2 Winner Prediction\n",
                "\n",
                "This notebook predicts the winner of a Dota 2 match (Radiant vs. Dire) based on game data.\n",
                "We use a combination of raw features, JSON match logs, and time-series data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Libraries\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "pd.set_option('display.max_columns', None)\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "%matplotlib inline\n",
                "\n",
                "import datetime\n",
                "import lightgbm as lgb\n",
                "from scipy import stats\n",
                "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold, cross_val_score, GridSearchCV, RepeatedStratifiedKFold\n",
                "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
                "import os\n",
                "import plotly.offline as py\n",
                "py.init_notebook_mode(connected=True)\n",
                "import plotly.graph_objs as go\n",
                "import plotly.tools as tls\n",
                "import xgboost as xgb\n",
                "import lightgbm as lgb\n",
                "from sklearn import model_selection\n",
                "from sklearn.metrics import accuracy_score, roc_auc_score\n",
                "from sklearn import metrics\n",
                "import json\n",
                "import ast\n",
                "import time\n",
                "from sklearn import linear_model\n",
                "import eli5\n",
                "from eli5.sklearn import PermutationImportance\n",
                "import shap\n",
                "from tqdm import tqdm_notebook\n",
                "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
                "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
                "from sklearn.neighbors import NearestNeighbors\n",
                "from sklearn.feature_selection import GenericUnivariateSelect, SelectPercentile, SelectKBest, f_classif, mutual_info_classif, RFE\n",
                "import statsmodels.api as sm\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "from catboost import CatBoostClassifier\n",
                "\n",
                "from IPython.display import HTML\n",
                "\n",
                "from plotly import tools\n",
                "import plotly.graph_objs as go\n",
                "from plotly.offline import init_notebook_mode, iplot\n",
                "warnings.filterwarnings(\"ignore\")\n",
                "init_notebook_mode(connected=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Data Loading"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "PATH = \"/kaggle/input/mlcourse-dota2-win-prediction/\"\n",
                "\n",
                "print(\"Loading data...\")\n",
                "train = pd.read_csv(os.path.join(PATH, 'train_features.csv'), index_col='match_id_hash')\n",
                "test = pd.read_csv(os.path.join(PATH, 'test_features.csv'), index_col='match_id_hash')\n",
                "targets = pd.read_csv(os.path.join(PATH, 'train_targets.csv'), index_col='match_id_hash')\n",
                "\n",
                "print(f\"Train shape: {train.shape}\")\n",
                "print(f\"Test shape: {test.shape}\")\n",
                "print(f\"Targets shape: {targets.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Feature Engineering\n",
                "We will process the raw JSON data to extract more detailed features about heroes, items, and events."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Function to read JSONL files\n",
                "def read_json_lines(file_path):\n",
                "    with open(file_path, 'r') as f:\n",
                "        for line in f:\n",
                "            yield json.loads(line)\n",
                "\n",
                "# Example: Extracting hero ids and basic stats from JSON (Simplified for baseline)\n",
                "# In a real scenario, we would iterate through 'train_matches.jsonl' and 'test_matches.jsonl'\n",
                "# and create a DataFrame of new features.\n",
                "\n",
                "# For this baseline, we will focus on the pre-computed 'train_features.csv' \n",
                "# but we'll add some aggregated features.\n",
                "\n",
                "full_df = pd.concat([train, test], sort=False)\n",
                "\n",
                "print(\"Feature engineering...\")\n",
                "# 1. Hero Combinations (One-Hot Encoding or Embeddings)\n",
                "# The dataset has columns like 'r1_hero_id', 'd1_hero_id', etc.\n",
                "hero_cols = [f'{t}{i}_hero_id' for t in ['r', 'd'] for i in range(1, 6)]\n",
                "\n",
                "# 2. Aggregated Stats (Gold, XP, Kills)\n",
                "for team in ['r', 'd']:\n",
                "    players = [f'{team}{i}' for i in range(1, 6)]\n",
                "    \n",
                "    # Sum of kills, deaths, assists\n",
                "    full_df[f'{team}_kills_sum'] = full_df[[f'{p}_kills' for p in players]].sum(axis=1)\n",
                "    full_df[f'{team}_deaths_sum'] = full_df[[f'{p}_deaths' for p in players]].sum(axis=1)\n",
                "    full_df[f'{team}_assists_sum'] = full_df[[f'{p}_assists' for p in players]].sum(axis=1)\n",
                "    \n",
                "    # Sum of gold and xp\n",
                "    full_df[f'{team}_gold_sum'] = full_df[[f'{p}_gold' for p in players]].sum(axis=1)\n",
                "    full_df[f'{team}_xp_sum'] = full_df[[f'{p}_xp' for p in players]].sum(axis=1)\n",
                "\n",
                "# 3. Differences (Radiant - Dire)\n",
                "full_df['kills_diff'] = full_df['r_kills_sum'] - full_df['d_kills_sum']\n",
                "full_df['gold_diff'] = full_df['r_gold_sum'] - full_df['d_gold_sum']\n",
                "full_df['xp_diff'] = full_df['r_xp_sum'] - full_df['d_xp_sum']\n",
                "\n",
                "# Split back into train and test\n",
                "X = full_df.loc[train.index]\n",
                "X_test = full_df.loc[test.index]\n",
                "y = targets['radiant_win'].astype(int)\n",
                "\n",
                "print(\"Data prepared.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Model Training (CatBoost)\n",
                "CatBoost is excellent for categorical features and robust to overfitting."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
                "\n",
                "model = CatBoostClassifier(\n",
                "    iterations=1000,\n",
                "    learning_rate=0.05,\n",
                "    depth=6,\n",
                "    eval_metric='AUC',\n",
                "    random_seed=42,\n",
                "    verbose=100,\n",
                "    task_type=\"GPU\" # Use GPU if available on Kaggle\n",
                ")\n",
                "\n",
                "model.fit(\n",
                "    X_train, y_train,\n",
                "    eval_set=(X_val, y_val),\n",
                "    early_stopping_rounds=50\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Evaluation & Interpretation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Feature Importance\n",
                "feature_imp = pd.DataFrame({'feature': X.columns, 'importance': model.feature_importances_})\n",
                "feature_imp = feature_imp.sort_values('importance', ascending=False).head(20)\n",
                "\n",
                "plt.figure(figsize=(12, 8))\n",
                "sns.barplot(x='importance', y='feature', data=feature_imp)\n",
                "plt.title('Top 20 Feature Importance')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# SHAP Values\n",
                "explainer = shap.TreeExplainer(model)\n",
                "shap_values = explainer.shap_values(X_val)\n",
                "\n",
                "shap.summary_plot(shap_values, X_val)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Submission"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "preds = model.predict_proba(X_test)[:, 1]\n",
                "\n",
                "submission = pd.DataFrame({'match_id_hash': X_test.index, 'radiant_win_prob': preds})\n",
                "submission.to_csv('submission.csv', index=False)\n",
                "\n",
                "print(\"Submission saved to submission.csv\")\n",
                "print(submission.head())"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}