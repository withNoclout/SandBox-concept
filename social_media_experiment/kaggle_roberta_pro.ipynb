{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Social Media Extremism Detection - RoBERTa PRO\n",
                "\n",
                "**Goal:** Break 0.90 Accuracy.\n",
                "**Strategy:**\n",
                "1.  **Model:** Upgrade to `roberta-large` (Smarter, slower).\n",
                "2.  **Technique:** Pseudo-Labeling (Use confident test predictions as new training data)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q transformers datasets torch scikit-learn simpletransformers"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "from sklearn.model_selection import StratifiedKFold\n",
                "from sklearn.metrics import accuracy_score\n",
                "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
                "import logging\n",
                "import torch\n",
                "\n",
                "logging.basicConfig(level=logging.INFO)\n",
                "transformers_logger = logging.getLogger(\"transformers\")\n",
                "transformers_logger.setLevel(logging.WARNING)\n",
                "\n",
                "cuda_available = torch.cuda.is_available()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "train = pd.read_csv(\"train.csv\")\n",
                "test = pd.read_csv(\"test.csv\")\n",
                "\n",
                "train['text'] = train['Original_Message'].fillna(\"\")\n",
                "test['text'] = test['Original_Message'].fillna(\"\")\n",
                "\n",
                "label_map = {'NON_EXTREMIST': 0, 'EXTREMIST': 1}\n",
                "train['labels'] = train['Extremism_Label'].map(label_map)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Configuration (The \"Pro\" Settings)\n",
                "*   `roberta-large`: Much bigger brain.\n",
                "*   `num_train_epochs`: 5 (Train longer).\n",
                "*   `learning_rate`: 1e-5 (Learn slower and more carefully)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_args = ClassificationArgs()\n",
                "model_args.num_train_epochs = 5\n",
                "model_args.train_batch_size = 8 # Smaller batch size for 'large' model to fit in GPU\n",
                "model_args.eval_batch_size = 16\n",
                "model_args.learning_rate = 1e-5\n",
                "model_args.max_seq_length = 128\n",
                "model_args.overwrite_output_dir = True\n",
                "model_args.save_model_every_epoch = False\n",
                "model_args.save_eval_checkpoints = False\n",
                "model_args.use_multiprocessing = False\n",
                "model_args.use_multiprocessing_for_evaluation = False\n",
                "model_args.manual_seed = 42"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Phase 1: Train `roberta-large` on 5 Folds"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
                "test_preds_list = []\n",
                "fold_scores = []\n",
                "\n",
                "print(\"--- Starting Phase 1: Training Base Models ---\")\n",
                "\n",
                "for fold, (train_idx, val_idx) in enumerate(skf.split(train, train['labels'])):\n",
                "    print(f\"\\n--- Fold {fold+1} ---\")\n",
                "    \n",
                "    train_df = train.iloc[train_idx][['text', 'labels']]\n",
                "    val_df = train.iloc[val_idx][['text', 'labels']]\n",
                "    \n",
                "    model = ClassificationModel(\n",
                "        \"roberta\",\n",
                "        \"roberta-large\", # <--- The Big Change\n",
                "        num_labels=2,\n",
                "        args=model_args,\n",
                "        use_cuda=cuda_available\n",
                "    )\n",
                "    \n",
                "    model.train_model(train_df)\n",
                "    \n",
                "    # Evaluate\n",
                "    result, model_outputs, wrong_predictions = model.eval_model(val_df)\n",
                "    preds = np.argmax(model_outputs, axis=1)\n",
                "    acc = accuracy_score(val_df['labels'], preds)\n",
                "    print(f\"Fold {fold+1} Accuracy: {acc:.4f}\")\n",
                "    fold_scores.append(acc)\n",
                "    \n",
                "    # Predict on Test\n",
                "    predictions, raw_outputs = model.predict(test['text'].tolist())\n",
                "    test_preds_list.append(raw_outputs) # Save raw logits for averaging\n",
                "\n",
                "print(f\"\\nPhase 1 Average Accuracy: {np.mean(fold_scores):.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Phase 2: Pseudo-Labeling\n",
                "We take the high-confidence predictions from Phase 1 and add them to the training set.\n",
                "This is a common trick to boost performance."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Average the logits from all 5 folds\n",
                "avg_logits = np.mean(test_preds_list, axis=0)\n",
                "# Convert to probabilities\n",
                "probs = torch.softmax(torch.tensor(avg_logits), dim=1).numpy()\n",
                "\n",
                "# Select confident predictions (> 0.90 confidence)\n",
                "high_conf_indices = np.where(np.max(probs, axis=1) > 0.90)[0]\n",
                "pseudo_labels = np.argmax(probs[high_conf_indices], axis=1)\n",
                "\n",
                "print(f\"Found {len(high_conf_indices)} high-confidence test samples to add.\")\n",
                "\n",
                "# Create Pseudo-Labeled Dataset\n",
                "pseudo_df = test.iloc[high_conf_indices][['text']].copy()\n",
                "pseudo_df['labels'] = pseudo_labels\n",
                "\n",
                "# Combine with original train\n",
                "full_train_df = pd.concat([train[['text', 'labels']], pseudo_df])\n",
                "print(f\"New Training Size: {len(full_train_df)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Phase 3: Final Training\n",
                "Train one final model on the combined dataset."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"--- Starting Phase 3: Final Training ---\")\n",
                "final_model = ClassificationModel(\n",
                "    \"roberta\",\n",
                "    \"roberta-large\",\n",
                "    num_labels=2,\n",
                "    args=model_args,\n",
                "    use_cuda=cuda_available\n",
                ")\n",
                "\n",
                "final_model.train_model(full_train_df)\n",
                "\n",
                "final_predictions, _ = final_model.predict(test['text'].tolist())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "inv_label_map = {0: 'NON_EXTREMIST', 1: 'EXTREMIST'}\n",
                "final_labels = [inv_label_map[p] for p in final_predictions]\n",
                "\n",
                "submission = pd.DataFrame({\n",
                "    'ID': test['ID'],\n",
                "    'Extremism_Label': final_labels\n",
                "})\n",
                "\n",
                "submission.to_csv(\"submission_roberta_pro.csv\", index=False)\n",
                "print(\"Saved submission_roberta_pro.csv\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}