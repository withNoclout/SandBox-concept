{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Social Media Extremism Detection - RoBERTa Baseline\n",
                "\n",
                "To hit 0.9+ accuracy, we need a model that understands **context**, not just keywords.\n",
                "This notebook uses **RoBERTa (Robustly Optimized BERT)**, which is the state-of-the-art for this size of data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q transformers datasets torch scikit-learn simpletransformers"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "from sklearn.model_selection import StratifiedKFold\n",
                "from sklearn.metrics import accuracy_score, classification_report\n",
                "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
                "import logging\n",
                "import torch\n",
                "\n",
                "logging.basicConfig(level=logging.INFO)\n",
                "transformers_logger = logging.getLogger(\"transformers\")\n",
                "transformers_logger.setLevel(logging.WARNING)\n",
                "\n",
                "# Check for GPU\n",
                "cuda_available = torch.cuda.is_available()\n",
                "print(f\"CUDA Available: {cuda_available}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Data Preparation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "train = pd.read_csv(\"train.csv\")\n",
                "test = pd.read_csv(\"test.csv\")\n",
                "\n",
                "# Simple Transformers expects columns: ['text', 'labels']\n",
                "train['text'] = train['Original_Message'].fillna(\"\")\n",
                "test['text'] = test['Original_Message'].fillna(\"\")\n",
                "\n",
                "# Map labels to integers\n",
                "label_map = {'NON_EXTREMIST': 0, 'EXTREMIST': 1}\n",
                "train['labels'] = train['Extremism_Label'].map(label_map)\n",
                "\n",
                "print(train.head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Configuration\n",
                "We use `roberta-base`. For even better results, try `roberta-large` (requires more GPU memory)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_args = ClassificationArgs()\n",
                "model_args.num_train_epochs = 3\n",
                "model_args.train_batch_size = 16\n",
                "model_args.eval_batch_size = 32\n",
                "model_args.learning_rate = 2e-5\n",
                "model_args.max_seq_length = 128\n",
                "model_args.overwrite_output_dir = True\n",
                "model_args.save_model_every_epoch = False\n",
                "model_args.save_eval_checkpoints = False\n",
                "model_args.use_multiprocessing = False\n",
                "model_args.use_multiprocessing_for_evaluation = False\n",
                "model_args.manual_seed = 42"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Training with Cross-Validation (5 Folds)\n",
                "This ensures our score is robust and not just luck."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
                "fold_scores = []\n",
                "test_preds_list = []\n",
                "\n",
                "for fold, (train_idx, val_idx) in enumerate(skf.split(train, train['labels'])):\n",
                "    print(f\"\\n--- Fold {fold+1} ---\")\n",
                "    \n",
                "    train_df = train.iloc[train_idx][['text', 'labels']]\n",
                "    val_df = train.iloc[val_idx][['text', 'labels']]\n",
                "    \n",
                "    # Initialize Model\n",
                "    model = ClassificationModel(\n",
                "        \"roberta\",\n",
                "        \"roberta-base\",\n",
                "        num_labels=2,\n",
                "        args=model_args,\n",
                "        use_cuda=cuda_available\n",
                "    )\n",
                "    \n",
                "    # Train\n",
                "    model.train_model(train_df)\n",
                "    \n",
                "    # Evaluate\n",
                "    result, model_outputs, wrong_predictions = model.eval_model(val_df)\n",
                "    \n",
                "    # Calculate Accuracy\n",
                "    preds = np.argmax(model_outputs, axis=1)\n",
                "    acc = accuracy_score(val_df['labels'], preds)\n",
                "    print(f\"Fold {fold+1} Accuracy: {acc:.4f}\")\n",
                "    fold_scores.append(acc)\n",
                "    \n",
                "    # Predict on Test Set\n",
                "    predictions, raw_outputs = model.predict(test['text'].tolist())\n",
                "    test_preds_list.append(predictions)\n",
                "\n",
                "print(f\"\\nAverage Accuracy: {np.mean(fold_scores):.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Submission (Majority Vote)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "test_preds_matrix = np.array(test_preds_list).T\n",
                "final_preds = []\n",
                "\n",
                "for row in test_preds_matrix:\n",
                "    final_preds.append(np.argmax(np.bincount(row)))\n",
                "\n",
                "# Map back to strings\n",
                "inv_label_map = {0: 'NON_EXTREMIST', 1: 'EXTREMIST'}\n",
                "final_labels = [inv_label_map[p] for p in final_preds]\n",
                "\n",
                "submission = pd.DataFrame({\n",
                "    'ID': test['ID'],\n",
                "    'Extremism_Label': final_labels\n",
                "})\n",
                "\n",
                "submission.to_csv(\"submission_roberta.csv\", index=False)\n",
                "print(\"Saved submission_roberta.csv\")\n",
                "print(submission.head())"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}